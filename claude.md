# Voice AI Agent Prototype - Learning Project

## Primary Goal
**Learn to build prototypes quickly** by building a voice AI advisor for the GreatInventions project.

This is a LEARNING PROJECT - the focus is on understanding architecture, making rapid decisions, and building end-to-end systems, not just shipping a product.

## Project Context

### GreatInventions Background
- Media project about engineering inventions, inventors, and product design
- Target audience: CEOs, deep tech founders, VCs, researchers
- Format: Newsletter ‚Üí Podcast ‚Üí Media empire
- **Context files:**
  - `/Users/sash/Documents/GreatInventions/PROJECT_GOALS.md`
  - `/Users/sash/Documents/GreatInventions/GreatInventions.md`
- **Published articles:**
  - WiFi (Hedy Lamarr's frequency hopping + CSIRO's OFDM)
  - Shipping Container (Malcolm McLean and globalization)
  - QR Code
- **Writing style:** Long-form, deeply researched, inventor-focused stories with technical depth and modern founder lessons

### Voice Agent Purpose
A conversational AI advisor that helps with:
- Choosing next topics to write about
- Marketing strategies
- Brainstorming ideas for the project
- General project advice

## Agent Specifications

### Personality - "Aloy"
- **Name:** Aloy (inspired by Horizon Zero Dawn character)
- **Role:** Brainstorming partner
- **Tone:** Energetic, conversational, fast-paced, strong and curious
- **Response style:** Brief (2-3 sentences max), asks 1-2 clarifying questions max, offers crisp actionable suggestions
- **Language:** Uses "we" language, occasionally challenges assumptions, proactively suggests ideas
- **Voice:** Female voice matching Aloy's character - strong, determined, curious (ElevenLabs)

### Technical Requirements
- Real-time back-and-forth conversation
- Low latency (feels like talking to a real person)
- Spacebar push-to-talk interaction
- Visual UI showing agent state with automatic transitions
- Full GreatInventions context (PROJECT_GOALS, published articles, writing style)
- Conversation memory across sessions (summary-based)

## Architecture

### High-Level Flow
```
User Voice ‚Üí STT ‚Üí Claude API ‚Üí TTS ‚Üí Audio Output
              ‚Üì                    ‚Üì
         Transcript          Audio Chunks
              ‚Üì                    ‚Üì
         Conversation         UI Feedback
           History          (listening/speaking)
```

### Component Stack

**1. Speech-to-Text (STT)**
- **Choice:** Deepgram (~$0.0043/min)
- Why: Fast, cheap, good quality, supports streaming
- Alternative: OpenAI Whisper for higher accuracy

**2. Conversation Engine**
- **Choice:** Claude API (Sonnet 4.5)
- Streaming enabled for low latency
- System prompt: Defines advisor persona + GreatInventions context
- Conversation history: Last 10-15 exchanges

**3. Text-to-Speech (TTS)**
- **Choice:** ElevenLabs (~$0.30/1K chars)
- Female voice (user-selected)
- Streaming enabled

**4. Desktop Application**
- **Choice:** Electron + Node.js
- Frontend: Simple HTML/CSS/JS or React
- Backend: WebSocket server orchestrating all services

### Latency Optimization Strategy

**Goal:** <2 second response time from user finishing speech to agent starting to speak

**Techniques:**
1. **Streaming everywhere:**
   - Deepgram: Real-time transcription via WebSocket
   - Claude: Stream tokens as generated
   - ElevenLabs: Stream audio chunks

2. **Sentence-level chunking:**
   - Don't wait for full Claude response
   - Send each complete sentence to TTS immediately
   - Play audio as soon as first chunk arrives

3. **Voice Activity Detection (VAD):**
   - Detect when user stops speaking
   - Start processing immediately
   - Support interruptions (stop playback if user speaks)

4. **Parallel processing:**
   - While sentence N is being spoken, sentence N+1 is being generated

### UI Design

**Visual Reference:** J&J screenshots - Siri-like spirit orb design

**Interface:**
- **Spirit orb:** Central radial gradient sphere with soft blur
- **State tag:** Pill-shaped label below orb showing current state
- **Color-coded states (automatic transitions):**
  - **Blue:** Idle/waiting for input (gentle pulse)
  - **Green:** Listening (press spacebar, amplitude-reactive animation)
  - **Purple:** Thinking/processing (rotation/flow effect)
  - **Orange/Yellow:** Speaking (waveform synced to audio)

**Interaction Flow:**
1. Press spacebar ‚Üí Green (Listening)
2. Release spacebar ‚Üí Purple (Thinking)
3. Aloy starts speaking ‚Üí Orange (Speaking)
4. Response complete ‚Üí Blue (Idle)

**Optional for debugging:**
- Live transcript display
- Latency metrics

### Memory System

**Conversation Summaries:**
After each conversation, Claude generates a summary containing:
- Date and time
- Topics discussed
- Ideas generated
- Decisions made
- Action items/next steps
- User's interests and priorities

**Storage:**
- Simple JSON file: `conversations/memory.json`
- Human-readable and editable
- Lightweight (summaries, not full transcripts)

**Context Loading:**
- On app startup, load last 10 conversation summaries
- Include in system prompt as "Previous conversations context"
- Enables continuity across sessions
- Keeps token usage low while maintaining memory

**Benefits:**
- Cost-effective (summaries vs full transcripts)
- Debuggable (can read/edit JSON directly)
- Scalable (can add search/export features later)
- Natural conversations ("Remember last time we discussed...")

### Budget Constraints

**Target:** <$10 for all iteration/testing

**Estimated costs per hour of conversation:**
- STT (Deepgram): $0.26
- Claude API: $0.45
- ElevenLabs: $0.90
- **Total: ~$1.60/hour** ‚Üí ~6 hours of testing with $10

## Tech Stack

**Application:**
- Electron (desktop app framework)
- Node.js (backend/orchestration)
- JavaScript/TypeScript (TBD based on learning preference)

**Frontend:**
- HTML/CSS for UI
- Web Audio API for mic input/speaker output
- Canvas or CSS animations for visualizations

**Backend Services:**
- Deepgram Node SDK
- Anthropic Claude SDK
- ElevenLabs Node SDK
- WebSocket for real-time communication

**Key Libraries:**
- `ws` - WebSocket server
- `@deepgram/sdk` - STT
- `@anthropic-ai/sdk` - Claude
- `elevenlabs-node` or API calls - TTS
- Audio processing libraries TBD

## Learning Objectives

Through this project, understand:

1. **Real-time audio processing:**
   - Capturing microphone input
   - Streaming audio to services
   - Playing back audio chunks

2. **API streaming patterns:**
   - How to stream from Claude API
   - Chunking strategies for low latency
   - Error handling in streaming contexts

3. **State management:**
   - Conversation state (listening ‚Üí processing ‚Üí speaking)
   - Conversation history management
   - Handling interruptions

4. **Electron/Desktop app basics:**
   - Setting up an Electron app
   - IPC between main/renderer processes
   - Packaging for distribution

5. **Prototype development skills:**
   - Making fast architectural decisions
   - Balancing quality vs speed
   - Iterating based on real usage

## Implementation Approach

### Phase 1: Foundation (Core Loop)
- Set up Electron app structure
- Implement basic STT ‚Üí Claude ‚Üí TTS pipeline
- Text-based testing (type instead of speak)
- Validate latency and response quality

### Phase 2: Audio Integration
- Add microphone input
- Integrate Deepgram streaming STT
- Integrate ElevenLabs streaming TTS
- Test end-to-end voice loop

### Phase 3: Optimization
- Implement sentence-level chunking
- Add VAD for better turn-taking
- Optimize buffering and streaming
- Measure and improve latency

### Phase 4: UI Polish
- Create visual feedback (listening/speaking indicators)
- Add conversation transcript display
- Smooth animations
- Error state handling

### Phase 5: Refinement
- Tune agent personality via system prompt
- Improve conversation context management
- Add features (pause, reset conversation, etc.)
- User testing and iteration

## Project Structure

```
voice-agent-prototype/
‚îú‚îÄ‚îÄ claude.md                 # This file
‚îú‚îÄ‚îÄ README.md                 # Setup instructions
‚îú‚îÄ‚îÄ package.json              # Dependencies
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.js              # Electron main process
‚îÇ   ‚îú‚îÄ‚îÄ preload.js           # Electron preload script
‚îÇ   ‚îú‚îÄ‚îÄ renderer/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index.html       # UI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ style.css        # Styling
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ app.js           # Frontend logic
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deepgram.js      # STT integration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ claude.js        # Conversation engine
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ elevenlabs.js    # TTS integration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ orchestrator.js  # Coordinates all services
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ audio.js         # Audio processing utilities
‚îÇ       ‚îî‚îÄ‚îÄ config.js        # API keys, settings
‚îî‚îÄ‚îÄ assets/
    ‚îî‚îÄ‚îÄ context/
        ‚îî‚îÄ‚îÄ project-goals.md # GreatInventions context
```

## Success Criteria

**Technical:**
- Consistent <2 second response latency
- Natural conversation flow with interruption support
- Stable audio quality
- No crashes during 10+ minute conversations

**Learning:**
- Understand each component well enough to modify
- Can explain architecture decisions
- Can extend/adapt for other use cases
- Comfortable with rapid prototyping workflow

**User Experience:**
- Feels like talking to a real brainstorming partner
- Agent responses are helpful for GreatInventions project
- UI clearly communicates agent state
- Overall experience feels "natural"

## Next Steps

1. Set up project structure
2. Install dependencies and configure API keys
3. Build minimal text-based conversation loop (STT/TTS mocked)
4. Add Claude integration with GreatInventions context
5. Integrate real voice services
6. Optimize latency
7. Polish UI
8. Test and iterate

## Notes & Decisions Log

_Document key decisions and learnings as we build..._

### Initial Planning - 2025-12-24

**Decision: Agent name "Aloy"**
- Inspired by Horizon Zero Dawn character
- Voice should match: strong, determined, curious
- Need to find matching ElevenLabs voice

**Decision: J&J screenshot visual design**
- Siri-like spirit orb with radial gradient
- Color-coded states: Blue (idle), Green (listening), Purple (thinking), Orange (speaking)
- Automatic state transitions based on agent state
- Pill-shaped tag showing current state

**Decision: Spacebar push-to-talk**
- Press spacebar to start listening
- Release to trigger processing
- States flow automatically from there
- Simpler and more reliable than VAD for v1

**Decision: Summary-based memory system**
- Store conversation summaries, not full transcripts
- JSON file for simplicity and debuggability
- Load last 10 summaries on startup
- Cost-effective while maintaining continuity

**Decision: Full GreatInventions context**
- Load PROJECT_GOALS and published articles
- Aloy should deeply know the project
- Include writing style and target audience

**Decision: Using Deepgram over alternatives**
- Rationale: Best balance of cost, speed, and accuracy for prototyping

**Decision: Electron over Tauri**
- Rationale: More mature ecosystem, easier to find examples (can revisit Tauri later for production)

**Decision: Sentence-level chunking for latency optimization**
- Rationale: Meaningful units that can be sent to TTS immediately without waiting for full response

**Decision: 7-iteration roadmap**
- Start with static UI to nail the visual design
- Add Claude text conversation before voice
- Build memory system early for better testing
- Add voice output, then input
- Optimize latency as separate phase
- Polish at the end

---

## Development Log

### Session 1 - 2025-12-24

**Completed: Iteration 1 - Core Functionality (80%)**

‚úÖ **Achievements:**
- Set up complete Electron app structure
- Implemented spirit orb visual with two-layer glow effect
  - Used CSS pseudo-elements (::before, ::after) for depth
  - Radial gradients with blur filters
- Created 4 color states: blue (idle), green (listening), purple (thinking), orange (speaking)
- Implemented CSS custom properties (variables) for state management
- Fixed CSS variable scoping (container-level for inheritance)
- Built spacebar interaction system:
  - Press spacebar ‚Üí listening
  - Release spacebar ‚Üí thinking
  - Auto-transition (1s) ‚Üí speaking
  - Auto-transition (2s) ‚Üí idle
- State machine with guards to prevent invalid transitions
- Proper event handling (keydown/keyup with preventDefault)

üìö **Learning Topics Covered:**
- Electron architecture (Main vs Renderer process)
- CSS pseudo-elements and layering
- CSS custom properties and inheritance
- Data attributes for state management
- JavaScript event listeners and event.code
- setTimeout and clearTimeout
- State machine patterns
- Git workflow and .gitignore best practices

‚è∏Ô∏è **Remaining for Iteration 1:**
- ~~Smooth color transitions (CSS transitions)~~ ‚úÖ
- ~~Animations (pulse, rotation, waveform effects)~~ ‚úÖ

**Status:** ‚úÖ **Iteration 1 COMPLETE!**

---

### Session 2 - 2025-12-24 (Continued)

**Completed: Iteration 1 - Polish & Refinement (100%)**

‚úÖ **Achievements:**
- Added smooth CSS transitions (0.3-0.4s) for color changes
- Implemented CSS animations using @keyframes
- Created two animation types:
  - `pulse-gentle` (4s) for idle state
  - `pulse-active` (1s) for all active states
- Simplified animation strategy (removed invisible rotation)
- Adjusted timing delays (3s thinking, 4s speaking) for better visibility
- Learned difference between CSS transitions vs animations

üìö **Learning Topics:**
- CSS transitions (reactive, one-time)
- CSS animations (@keyframes, infinite loops)
- Transform property composition
- Animation timing functions
- When to use transitions vs animations

---

### Session 2 (Continued) - 2025-12-24

**Completed: Iteration 2 - Text-Based Conversation (95%)**

‚úÖ **Achievements:**
- Set up Claude API with secure environment variables (.env)
- Installed Anthropic SDK and configured for Electron
- Created comprehensive system prompt for Aloy personality
- Built chat interface (two-panel layout: orb left, chat right)
- Integrated Claude API with conversation history
- Implemented full message flow: user ‚Üí thinking ‚Üí Aloy responds ‚Üí speaking
- Refined Aloy's personality to match Horizon game character:
  - Efficient, stoic, direct
  - Brief responses (1-2 sentences)
  - No excessive enthusiasm
  - Matter-of-fact tone
- Chat panel designed to be easily removable for voice-only mode later

üìö **Learning Topics:**
- API key management and security (.env files)
- Anthropic Claude SDK integration
- Async/await patterns in JavaScript
- System prompts and AI personality design
- DOM manipulation (adding messages dynamically)
- Conversation history management
- Two-panel flexbox layout
- Node.js integration in Electron (nodeIntegration)

üéØ **What Works:**
- Chat with Aloy about GreatInventions topics
- She knows all published articles (WiFi, Container, QR)
- Maintains conversation context
- Responds with focused, actionable suggestions
- Orb states sync with conversation (idle ‚Üí thinking ‚Üí speaking)

**Status:** ‚úÖ **Iteration 2 COMPLETE!**

---

### Session 3 - 2025-12-25

**Completed: Iteration 2 - Streaming Responses (100%)**

‚úÖ **Achievements:**
- Implemented streaming responses for real-time text display
- Modified `sendMessageToAloy` to use `sendMessageStreaming` function
- Aloy's responses now appear word-by-word instead of all at once
- Orb transitions to 'speaking' state immediately when first token arrives
- Auto-scroll keeps latest text visible during streaming
- Conversation feels more responsive and natural

üìö **Learning Topics:**
- Streaming API patterns with Claude SDK
- Real-time DOM updates with callbacks
- Managing state transitions during streaming
- UX improvements through progressive rendering

üéØ **What Works:**
- Full streaming conversation experience
- Smooth state transitions (thinking ‚Üí speaking on first token)
- Responsive UI that updates as tokens arrive
- Better perceived latency and engagement

**Next Session:** Iteration 3 - Memory System (conversation summaries across sessions), or Iteration 4 - Voice Output (TTS)

---

### Session 3 (Continued) - 2025-12-25

**Completed: Iteration 3 - Memory System (100%)**

‚úÖ **Achievements:**
- Built complete memory service with conversation summaries
- Implemented reliable save-on-close using raw messages (no async issues)
- Auto-converts raw messages to summaries on app startup
- Memory context loaded and included in system prompt
- "Clear Memory" button with confirmation dialog
- Dual-format storage: raw (instant save) ‚Üí summary (background processing)
- No data loss even with < 6 messages

üìö **Learning Topics:**
- File system operations in Node.js (fs.readFileSync, fs.writeFileSync)
- JSON storage patterns for small data
- Async timing issues with window.beforeunload
- Background processing on app startup
- Synchronous vs asynchronous save strategies
- Type-based data structures (raw vs summary)

üéØ **What Works:**
- Conversations saved automatically every 6 messages
- Raw messages saved instantly on app close (reliable!)
- Raw messages converted to summaries on next startup
- Aloy remembers previous conversations across sessions
- Clear Memory button resets everything
- Memory file is human-readable and editable JSON

üîß **Technical Solution:**
- Problem: beforeunload with async API calls was unreliable
- Solution: Save raw messages (synchronous), summarize later
- Format: `{type: "raw", messages: [...]}` ‚Üí `{type: "summary", summary: "..."}`
- Memory loads last 10 summaries into system prompt

**Next Session:** Iteration 4 - Voice Output (TTS with ElevenLabs), or Iteration 5 - Voice Input (STT with Deepgram)

---

### Session 4 - 2025-12-25 (Continued)

**Completed: Iteration 4 - Voice Output (100%)**

‚úÖ **Achievements:**
- Integrated ElevenLabs TTS for voice output
- Implemented sentence-level streaming for low latency
- Built parallel TTS generation (up to 2 concurrent requests)
- Created order-preserving audio playback system
- Fixed audio scrambling with Map-based ordering
- Cleaned up dead code (removed test files)

üìö **Learning Topics:**
- ElevenLabs API and ReadableStream handling
- Sentence extraction with regex
- Parallel vs sequential processing trade-offs
- Race condition handling in async operations
- Audio playback with HTML5 Audio API
- Blob/ObjectURL memory management
- Rate limiting (ElevenLabs: 2 concurrent max)

üéØ **What Works:**
- Aloy speaks responses with natural voice
- Parallel TTS generation (low latency)
- Sequential playback (correct order)
- Text and audio appear simultaneously
- Order preserved even when TTS completes out of sequence

üîß **Technical Implementation:**
```
Streaming text ‚Üí Extract sentences ‚Üí Parallel TTS (max 2) ‚Üí
Store in Map with order index ‚Üí Play in sequence
```

**Key Innovation:**
- Order tracking with `Map<orderIndex, audioBuffer>`
- `nextOrderIndex++` when queuing
- `nextPlayIndex++` when playing
- Handles race conditions where fast sentences finish before slow ones

**Next Session:** Iteration 5 - Voice Input (STT with Deepgram)

---

### Session 5 - 2025-12-25 (Continued)

**Completed: Iteration 5 - Voice Input (100%)**

‚úÖ **Achievements:**
- Integrated Deepgram STT for speech-to-text
- Implemented spacebar push-to-talk
- Real-time transcription (interim results show as you speak)
- Web Audio API microphone capture
- PCM16 audio format conversion
- Hybrid mode (text + voice both work)
- Fixed Bluetooth compatibility (uses native sample rate)

üìö **Learning Topics:**
- Deepgram Live Transcription API
- Web Audio API (AudioContext, MediaStreamSource, ScriptProcessorNode)
- getUserMedia() for microphone access
- Float32 ‚Üí PCM16 audio conversion
- Sample rate handling (48kHz native vs 16kHz optimal)
- Bluetooth audio device limitations
- WebSocket bidirectional streaming

üéØ **What Works:**
- Hold spacebar ‚Üí Record voice ‚Üí Release ‚Üí Aloy responds
- See words appear in input field as you speak
- Same Claude flow as text input
- Full voice conversation loop working

üîß **Technical Implementation:**
```
Mic ‚Üí MediaStreamSource ‚Üí ScriptProcessorNode ‚Üí
Float32 audio ‚Üí Convert to PCM16 ‚Üí Send to Deepgram ‚Üí
Receive transcript ‚Üí Send to Claude ‚Üí TTS ‚Üí Audio response
```

**Key Learnings:**
- Bluetooth devices (AirPods) need native sample rate
- ScriptProcessorNode deprecated but simpler than AudioWorklet
- Must connect processor to destination for callbacks to fire
- `isRecording` flag prevents audio leak after release

**Challenges Solved:**
1. **Bluetooth AirPods silent audio:** Fixed by using native sample rate instead of forcing 16kHz
2. **Audio continues after release:** Added `isRecording` flag for immediate stop
3. **Empty transcripts:** Sample rate mismatch - changed to 48kHz

**Status:** ‚úÖ **Full voice conversation working!**


---

## Next Session Planning - 2025-12-25

**Discussion Topic:** Making voice chat more interactive

**Decision:** Implement Iteration 6 - Interruption + Latency Optimization

### Interruption Design Discussion

**Question posed:** When user interrupts Aloy mid-sentence, what happens?

**Options considered:**

**Option A: Discard & Fresh Response** ‚≠ê CHOSEN
- Stop Aloy immediately
- Clear all queues and state
- User speaks new question
- Aloy generates fresh response to new question
- Original response discarded completely

**Option B: Queue & Resume** ‚ùå Rejected
- Save interrupted response state
- Handle new question
- Resume original response afterward
- Too complex, awkward UX

**Option C: Smart Context Switch** ‚ùå Rejected
- AI determines if interruption is related
- Integrate or discard based on context
- Very complex, adds latency

**Rationale for Option A:**
- Natural conversation flow (humans don't "resume" after interruption)
- Simple implementation (~15 lines)
- No queue management complexity
- User interrupts BECAUSE they want to change direction
- Clean state reset

### Implementation Plan

**Part 1: Interruption**
- Create `stopAloyCompletely()` function
- Modify spacebar keydown to allow interruption during 'speaking' state
- Clear all queues: sentenceQueue, audioBuffers, currentAudio
- Reset indices: nextOrderIndex, nextPlayIndex
- Start fresh recording

**Part 2: Latency Optimization**
- Reduce stopRecording() wait: 500ms ‚Üí 200ms
- Parallelize Claude start with Deepgram finalization
- Profile timing to measure improvements
- Target: <3s total response time (from ~5.3s)

**Edge Cases:**
- Rapid interruptions (last one wins)
- Interrupt during thinking (allow)
- Interrupt during first sentence (same behavior)

**Files to update:**
- `src/renderer/app.js` - Main implementation
- Documentation updated (ROADMAP.md, NEXT_SESSION.md)

**Status:** Ready to implement in next session

See `NEXT_SESSION.md` for detailed implementation plan.

